\newif\ifdebug
%\debugtrue
\ifdebug
\documentclass[12pt,a4paper]{ctexrep}
\usepackage[a4paper, portrait, margin=0.8in]{geometry}
\usepackage{graphicx} % Required for inserting images
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{markdown}
%\usepackage{china2e} 
\usepackage[utf8]{inputenc}
\begin{document}
\fi

\chapter{Probability Theory概率论}
Introduction to Probability Theory, Conditional Probability, Independence and Expectation, Solving Problems using Linearity of Expectation, Markov Chains
\section{定义}
\subsection{基本定义}
Extended Real number: $\mathbb{R}\cup \{-\infty,+\infty\}$. Positive extended reals:$\overline{\mathbb{R}} = [0,+\infty) \cup \{+\infty\}$

Let $A$ be a set and $E \subseteq \mathbb{P}(A)$

Measure: A measure $\mu$ is a function that maps $E$ to $\overline{\mathbb{R}}$

Measure Space: $(A,E,\mu)$. $A$ is the sample space, $E$ is the event space, and $\mu$ is the probability function.

Properties of measure spaces:($\emptyset \in E, \mu(\emptyset) = 0$), (Let $x_1,x_2,x_3\dots \in E$ be countable sets of pairwise disjoint sets, then $\cup_{i=0}^{\infty} x_i\in E, \mu(\cup_{i=0}^{\infty} x_i) = \sum(\cup_{i=0}^{\infty} x_i)$), (if $x \in E$, then $x^C = A \setminus x \in E$)

Lebesque Measure: For every segment from $a$ to $b$, the measure is $(b,a)$. $\mu(\mathbb{R}) = \cup_{i\in \mathbb{Z}} [i,i+1) = \infty$

Probability Space: A probability space $(S,E,Prob)$ is a measure space with total measure 1, i.e. $Prob(S) = 1$. Probability space also satisfies the properties of measure spaces.\\

Conditional Probability: $P(A|B) = \frac{P(A\cap B}{P(B)}$. It's also denoted as $P_B(A)$

Independent events: $A$ and $B$ are independent events if $P(A|B) = P(A)$. Then, they satisfy: $P(AB) = P(A)\times P(B)$

Random Variable: A function $X: S \mapsto \mathbb{R}$. We say $X$ is a discrete random variable if $range(X)$ is either finite or countable

Expectation: $E[X] = \sum_{i = 1}^{\infty} x_i P(X = x_i)$

Stochastic Process: A sequence $x_0,x_1,x_2,\dots$ of random variables.

Markov Chains 见“重要定理详解”
\section{定理/结论}
Linearity of expectation: $A$ and $B$ are two random variables, then $E[aA+B] = aE[A]+E[B]$
\section{重要定理详解}
\subsection{Markov Chain}
Markov Chain: Let $Q$ be a finite set and $\forall i, range(x_i) \subseteq Q$, we say $x_1,x_2,\dots$ is a Markov chain if $\forall n, \forall q \in Q, P(x_n = q_n|x_{n-1} = q_{n-1}) = P(x_n = q_n|x_{n-1} = q_{n-1},x_{n-2} = q_{n-2},\dots,x_{1} = q_{1}$. 即后一项只看前一项，不看再之前的所有项

Markov Chain(Definition using graphs): In $C = (G,\pi,v_0)$ where $G = (V,E)$ is a directed graph, $\pi$ is a function: $E\mapsto [0,1]$ such that for $\forall u \in V, \sum_{v} \pi(u,v) = 1$.($\pi$ is a function that maps all edges to a probability, and the sum of each outgoing edge from a vertex is always 1). Define the probability space $(S,F,P)$, where $S$ is all infinite walks starting from $v_0$, and $F$ is all events, i.e. the extensions of finite paths and anything that can be obtained by their unions/ intersections/ complement. $P$ is the probability function.

Extension: Let $w$ be a finite walk on $G$, then $Ext(w) = \{\overline{w} \in G| \overline{w}$ is an infinite walk with prefix $w\}$

B\"uchi set: There's a target set $T\subseteq V$. $A_i = \{w|w$ is a finite walk on $G$ and exists $i$ $k$s such that all $w[k] \in T\}$. $B_i = Ext(A_i)$. $A_i$ are countable sets, so $B_i$ are countable union of events. $B\ddot{u}chi(T) = \cap_{i=1}^n B_i$ is an event.
%需要继续整理这块

精神状态不正常了：反正就是B\"uchi(v)会无限次的经过v，然后可将一个非Strongly Connected 的graph切分成一堆Strongly Connected Component。在每一个SCC中，一定会有Bottom SCC，即只有ingoing没有outgoing edge。P（最后end up in BSCC） = 1。%这是彩蛋

精神正常后的补充：在一个SCC中，若有一个$v$会被无限次经过，即B\"uchi(v)成立，假设$v'$是$v$的一个successor，那么有限次经过$v'$的概率=$p^n(1-p)^{\infty}$，趋近于0，所以$P(Buchi[v']|Buchi[v])=1$. By conditional probability, $P(Buchi[v'])\geq P(Buchi[v])$. 又因为 $\forall v \in SCC, S=\cup Buchi[v], P(S)=1$，所以肯定有一个$P(Buchi[v])=1$，那么$\forall v \in SCC, P(Buchi[v])=1$。

在一个G中有很多SCC，其中必包含BSCC，那么$P(Buchi[v])$在$v\in BSCC$ 时与上一题相同，而$P(Buchi[v])$在$v \notin BSCC$时=0，因为最后肯定会卡在一个BSCC里，不在BSCC里的点必不会无限次经过

\subsection{Markov decision process}
State space $S$, Action space $A$, State Transitional Probability Matrix $Prob(u,v)$, Reward $Reward(e)$, Discount factor $\gamma$, Policy $Policy(u)$. Refer to an example in Hw4: 

Define function $\bold{EVALUATION}$, input policy at each vertex, and output the modified state values:

For each state $u$, let $v_1,v_2,\dots, v_x$ be all the vertices that $(u,v_i)\in E$, the new state value of $u$ is :\[V(u)=\sum_{i=1}^{x} Policy(u,v_i)\times Prob(u,v_i)\times (Reward(v_i)+\gamma V(v_i))\]. If the new $V(u)$ is very close to the original $V(u)$, then terminate.\\

Define function $\bold{IMPROVE}$, input the policy before and outputs the modified policies:

For each state $u$, let $v_1,v_2,\dots, v_x$ be all the vertices that $(u,v_i)\in E$, set $V(v_m)$ is maximum in all $V(v_i)$, then set $Policy(u,v_m)$ to 1 and all other $Policy(u,v_i)$ to 0. \\

The method is to loop through functions $\bold{EVALUATION}$ and $\bold{IMPROVE}$ again and again. After each time function $\bold{IMPROVE}$ is called, check if the policy before is the same as the policy after modifying. If it's the same, then stop.
%\section{方法}
\section{典型例题}
\subsection{Monty Hall Problem}
有三扇门，其中一扇有奖励，另两个惩罚。玩家先选择一个，然后主持人会打开一个没有奖励的门，此时玩家是否应该换选另一扇仍关着的门？——要换！

Construct a tuple (prize, choice, opened\_door)
\begin{center}
\begin{tabular}{|c|c|c|}
\hline
(1,1,2),(1,1,3) & (1,2,3) & (1,3,2)\\
\hline
(2,1,3) & (2,2,1),(2,2,3) & (2,3,1)\\
\hline
(3,1,2) & (3,2,1) & (3,3,1),(3,3,2)\\
\hline
\end{tabular}
\end{center}
Suppose I chose 1 and the host opens 2, what is the probability of prize in 1? \[P = \frac{P(1,1,2)}{P(1,1,2)+P(3,1,2)} = \frac{1/18}{1/18+1/9} = \frac{1}{3}\]
\subsection{Sleeping Beauty Problem}
玩家在床上睡着了，一个人翻了正常的一枚硬币，如果是正面就把玩家叫醒1次，如果是背面就把玩家叫醒2次。假设玩家无记忆。玩家每次醒来要猜硬币的正反，问玩家猜正还是反赢的概率大？——猜反面！

$E[$正面$] = \frac{1}{2}\times 1 + \frac{1}{2}\times 0 = \frac{1}{2}$

$E[$反面$] = \frac{1}{2}\times 0 + \frac{1}{2}\times 2 = 1$
\subsection{Cancer test}
有一个检测癌症的试纸，如果有癌，则以0.9的概率汇报“+”，如果没癌，则以0.9的概率汇报“-”。假设这个人得癌的概率是p。问得到“+”的汇报有多大概率得了癌症？——$\frac{0.9p}{0.8p+0.1}$

\[P(C|T^+) = \frac{P(C\cap T^+)}{P(T^+)} = \frac{P(T^+|C)P(C)}{P(C)P(T^+|C)+P(C^C)P(T^+|C^C)} = \frac{0.9p}{0.9p+0.1(1-p)} = \frac{0.9p}{0.8p+0.1}\]

\subsection{The Average Number of Times a Coin Needs to Be Flipped Until Head Appears}
有一个正常的硬币，求翻硬币直到翻到为正面向上所需次数的期望。(几何分布Geometric distribution)

法一：Let $X$ be the number of times we need to flip the coin before a Heads appear.

$E[X] = 0.5\times 1 + 0.25\times 2 + \dots + (0.5)^n \times n = 2$

法二：Let $\mu := E[X]$ then $\mu = \frac{1}{2}\times 1 + \frac{1}{2}(1+\mu)$, $\mu = 2$. Explanation: there's a $\frac{1}{2}$ chance of flipping to heads on the first try, and a $\frac{1}{2}$ chance of flipping to tails on the first try and needs a second chance, still with the same expectation.

EXTEND: 改为有一个正面概率为p的硬币：

法一：$E[X'] = \sum_{i=1}^{\infty} (1-p)^{i-1} \times p \times i = \frac{1}{p}$

法二：$E[X'] = p \times 1 + (1-p) \times (1+E[X'])$, Solve the equation, $E[X'] = \frac{1}{p}$

\subsection{Coupon Collector}
一共有n种coupon，每天能随机买一种coupon，问买到所有coupon所需天数的期望

Let $X$ be the number of days we need to collect all coupons. Set $X_i$ as the number of days for going from $i$ coupons to $i+1$ coupons. Then, $X = \sum_{i=0}^{n-1} X_i$, $E(X) = \sum_{i=0}^{n-1} E(X_i)$.

After $i$ types of collected coupons, the next new type of coupon has a $\frac{n-i}{n}$ probability of appearing. So $E(X_i) = \frac{n}{n-i}$. Then $E(X) = \sum_{i=0}^{n-1} \frac{n}{n-i} = n \sum_{i=0}^{n-1}\frac{1}{n-i} = n \sum_{i=1}^{n} \frac{1}{n} = ne$
\ifdebug
\end{document}
\fi